{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Activation\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from utils.data_manager import ClutteredMNIST\n",
    "from utils.visualizer import plot_mnist_sample\n",
    "from utils.visualizer import print_evaluation\n",
    "from utils.visualizer import plot_mnist_grid\n",
    "from components.STN import BilinearInterpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"./datasets/mnist_cluttered_60x60_6distortions.npz\"\n",
    "batch_size = 256\n",
    "num_epochs = 30\n",
    "\n",
    "data_manager = ClutteredMNIST(dataset_path)\n",
    "train_data, val_data, test_data = data_manager.load()\n",
    "x_train, y_train = train_data\n",
    "plot_mnist_sample(x_train[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_dim = 64\n",
    "latent_dim = 6\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Input(shape=(60, 60, 1))\n",
    "locnet = Flatten()(image)\n",
    "locnet = Dense(intermediate_dim, activation='relu')(locnet)\n",
    "\n",
    "locnet_mean = Dense(latent_dim)(locnet)\n",
    "locnet_var = Dense(latent_dim)(locnet)\n",
    "\n",
    "z_where = Sampling()((locnet_mean, locnet_var))\n",
    "\n",
    "x = BilinearInterpolation((30, 30))([image, z_where])\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(32, (3, 3))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(num_classes)(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "model = Model(inputs=image, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = - 0.5 * tf.reduce_mean(\n",
    "        locnet_var - tf.square(locnet_mean) - tf.exp(locnet_var) + 1)\n",
    "model.add_loss(kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-1)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 60, 60, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 3600)         0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           230464      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 6)            390         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 6)            390         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_2 (Sampling)           (None, 6)            0           dense_11[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_interpolation_2 (Bilin (None, 30, 30, 1)    0           input_3[0][0]                    \n",
      "                                                                 sampling_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 30, 30, 32)   320         bilinear_interpolation_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 30, 30, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 32)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 13, 13, 32)   9248        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 13, 13, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 32)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1152)         0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          295168      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 256)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 10)           2570        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 10)           0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square (TensorFlowO [(None, 6)]          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 6)]          0           dense_12[0][0]                   \n",
      "                                                                 tf_op_layer_Square[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp (TensorFlowOpLa [(None, 6)]          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 6)]          0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 tf_op_layer_Exp[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 6)]          0           tf_op_layer_Sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [()]                 0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [()]                 0           tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf_op_layer_Mul[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 538,550\n",
      "Trainable params: 538,550\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3140 - val_loss: 2.3143\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3127 - val_loss: 2.3159\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3142 - val_loss: 2.3192\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3132 - val_loss: 2.3122\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 2.3142 - val_loss: 2.3118\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3141 - val_loss: 2.3269\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 2.3129 - val_loss: 2.3084\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3136 - val_loss: 2.3176\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 2.3140 - val_loss: 2.3096\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 2.3133 - val_loss: 2.3179\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3141 - val_loss: 2.3075\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3131 - val_loss: 2.3254\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3135 - val_loss: 2.3130\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3147 - val_loss: 2.3165\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 2.3138 - val_loss: 2.3052\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 2.3135 - val_loss: 2.3175\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 2.3138 - val_loss: 2.3126\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3133 - val_loss: 2.3066\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 2.3137 - val_loss: 2.3163\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3140 - val_loss: 2.3260\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3139 - val_loss: 2.3258\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 2.3137 - val_loss: 2.3151\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3141 - val_loss: 2.3239\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3146 - val_loss: 2.3228\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 2.3133 - val_loss: 2.3102\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3132 - val_loss: 2.3263\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3140 - val_loss: 2.3166\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 2.3133 - val_loss: 2.3156\n",
      "Epoch 29/100\n",
      "1048/1407 [=====================>........] - ETA: 7s - loss: 2.3132"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-960e59c8f06b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/monash/test/variational_auto_encoder/venv2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/monash/test/variational_auto_encoder/venv2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/monash/test/variational_auto_encoder/venv2/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/monash/test/variational_auto_encoder/venv2/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/monash/test/variational_auto_encoder/venv2/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/monash/test/variational_auto_encoder/venv2/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0madd_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_steps\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0madd_seen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/monash/test/variational_auto_encoder/venv2/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/monash/test/variational_auto_encoder/venv2/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = model.input\n",
    "output_STN = model.get_layer('bilinear_interpolation_1').output\n",
    "\n",
    "STN_function = tf.keras.backend.function([input_image], [output_STN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_grid(x_train[20:30])\n",
    "plot_mnist_grid(x_train[20:30], STN_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_latest",
   "language": "python",
   "name": "tf_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
