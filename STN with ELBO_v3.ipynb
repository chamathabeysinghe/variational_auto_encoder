{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVariational Autoencoder with a STN and Modified Loss function\\n\\nThis is a MNIST classifier \\n\\nEncoder(Localizaton network) -> CNN to predict affine transformation matrix\\nSTN -> Apply affine transformation\\nDecoder -> CNN to classify transformed images from STN\\n\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Variational Autoencoder with a STN and Modified Loss function\n",
    "\n",
    "This is a MNIST classifier \n",
    "\n",
    "Encoder(Localizaton network) -> CNN to predict affine transformation matrix\n",
    "STN -> Apply affine transformation\n",
    "Decoder -> CNN to classify transformed images from STN\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Activation\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from utils.data_manager import ClutteredMNIST\n",
    "from utils.visualizer import plot_mnist_sample\n",
    "from utils.visualizer import print_evaluation\n",
    "from utils.visualizer import plot_mnist_grid\n",
    "from components.STN import BilinearInterpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"./datasets/mnist_cluttered_60x60_6distortions.npz\"\n",
    "batch_size = 256\n",
    "num_epochs = 30\n",
    "\n",
    "data_manager = ClutteredMNIST(dataset_path)\n",
    "train_data, val_data, test_data = data_manager.load()\n",
    "x_train, y_train = train_data\n",
    "plot_mnist_sample(x_train[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "  \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               latent_dim=6,\n",
    "               intermediate_dim=64,\n",
    "               name='encoder',\n",
    "               **kwargs):\n",
    "    super(Encoder, self).__init__(name=name, **kwargs)\n",
    "    self.conv_1 = layers.Conv2D(20, (5, 5), padding='same', activation='relu')\n",
    "    self.max_1 = layers.MaxPool2D(pool_size=(2, 2))\n",
    "    self.conv_2 = layers.Conv2D(20, (5, 5), activation='relu')\n",
    "    self.max_2 = layers.MaxPool2D(pool_size=(2, 2))\n",
    "    \n",
    "    self.flatten = layers.Flatten()\n",
    "    \n",
    "    self.dense_1 = layers.Dense(50, activation='relu')\n",
    "    \n",
    "    self.dense_mean = layers.Dense(latent_dim)\n",
    "    self.dense_log_var = layers.Dense(latent_dim)\n",
    "    \n",
    "    self.sampling = Sampling()\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.conv_1(inputs)\n",
    "    x = self.max_1(x)\n",
    "    x = self.conv_2(x)\n",
    "    x = self.max_2(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense_1(x)\n",
    "    z_mean = self.dense_mean(x)\n",
    "    z_log_var = self.dense_log_var(x)\n",
    "    z = self.sampling((z_mean, z_log_var))\n",
    "    return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "  \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               num_classes,\n",
    "               intermediate_dim=64,\n",
    "               name='decoder',\n",
    "               **kwargs):\n",
    "    super(Decoder, self).__init__(name=name, **kwargs)\n",
    "    self.conv_1 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n",
    "    self.max_1 = layers.MaxPool2D(pool_size=(2, 2))\n",
    "    self.conv_2 = layers.Conv2D(32, (3, 3), activation='relu')\n",
    "    self.max_2 = layers.MaxPool2D(pool_size=(2, 2))\n",
    "    self.flatten = layers.Flatten()\n",
    "    self.dense_1 = layers.Dense(256, activation='relu')\n",
    "#     self.dense_output = layers.Dense(num_classes, activation='softmax')\n",
    "    self.dense_output = layers.Dense(num_classes)\n",
    "\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.conv_1(inputs)\n",
    "    x = self.max_1(x)\n",
    "    x = self.conv_2(x)\n",
    "    x = self.max_2(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense_1(x)\n",
    "    x = self.dense_output(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(tf.keras.Model):\n",
    "  \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               num_classes,\n",
    "               intermediate_dim=64,\n",
    "               latent_dim=6,\n",
    "               name='autoencoder',\n",
    "               **kwargs):\n",
    "    super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
    "    self.num_classes = num_classes\n",
    "    self.encoder = Encoder(latent_dim=latent_dim,\n",
    "                           intermediate_dim=intermediate_dim)\n",
    "    self.stn = BilinearInterpolation((30, 30), name='stn_layer')\n",
    "    self.decoder = Decoder(num_classes, intermediate_dim=intermediate_dim)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var, z_where = self.encoder(inputs)\n",
    "    transformed_image = self.stn([inputs, z_where])\n",
    "    classification = self.decoder(transformed_image)\n",
    "    # Add KL divergence regularization loss.\n",
    "#     kl_loss = - 0.5 * tf.reduce_mean(\n",
    "#         z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "#     self.add_loss(kl_loss)\n",
    "    return classification, transformed_image, [z_mean, z_log_var, z_where]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "vae = VariationalAutoEncoder(num_classes, 64, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "crossentropy_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "iterations = x_train.shape[0] // batch_size\n",
    "loss_metric = tf.keras.metrics.Mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):  \n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for batch_arg in range(iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            arg_0 = batch_arg * batch_size\n",
    "            arg_1 = (batch_arg + 1) * batch_size\n",
    "            x_batch, y_batch = x_train[arg_0:arg_1], y_train[arg_0:arg_1]\n",
    "            y_batch = y_batch.astype('float32')\n",
    "            \n",
    "            classification, transformed_image, (z_mean, z_log_var, z_where) = vae(x_batch)\n",
    "            \n",
    "            cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=classification, labels=y_batch)\n",
    "            logpx_z = -tf.reduce_sum(cross_ent, axis=[1])\n",
    "            logpz = log_normal_pdf(z_where, 0., 0.)\n",
    "            logqz_x = log_normal_pdf(z_where, z_mean, z_log_var)\n",
    "            loss =  -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "            \n",
    "            \n",
    "#             loss = crossentropy_loss_fn(y_batch, classification)\n",
    "#             loss += sum(vae.losses)\n",
    "        \n",
    "        grads = tape.gradient(loss, vae.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "        \n",
    "        loss_metric(loss)\n",
    "\n",
    "        if batch_arg % 10 == 0:\n",
    "          print('step %s: mean loss = %s' % (batch_arg, loss_metric.result()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vae(x_train[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[2][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_grid(x_train[20:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_grid(result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_latest",
   "language": "python",
   "name": "tf_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
