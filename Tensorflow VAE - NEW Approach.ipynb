{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-dev20200317'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_metric = tf.keras.metrics.Mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "  \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               latent_dim=32,\n",
    "               intermediate_dim=64,\n",
    "               name='encoder',\n",
    "               **kwargs):\n",
    "    super(Encoder, self).__init__(name=name, **kwargs)\n",
    "    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
    "    self.dense_mean = layers.Dense(latent_dim)\n",
    "    self.dense_log_var = layers.Dense(latent_dim)\n",
    "    self.sampling = Sampling()\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense_proj(inputs)\n",
    "    z_mean = self.dense_mean(x)\n",
    "    z_log_var = self.dense_log_var(x)\n",
    "    z = self.sampling((z_mean, z_log_var))\n",
    "    return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "  \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               original_dim,\n",
    "               intermediate_dim=64,\n",
    "               name='decoder',\n",
    "               **kwargs):\n",
    "    super(Decoder, self).__init__(name=name, **kwargs)\n",
    "    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
    "    self.dense_output = layers.Dense(original_dim, activation='sigmoid')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense_proj(inputs)\n",
    "    return self.dense_output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(tf.keras.Model):\n",
    "  \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               original_dim,\n",
    "               intermediate_dim=64,\n",
    "               latent_dim=32,\n",
    "               name='autoencoder',\n",
    "               **kwargs):\n",
    "    super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
    "    self.original_dim = original_dim\n",
    "    self.encoder = Encoder(latent_dim=latent_dim,\n",
    "                           intermediate_dim=intermediate_dim)\n",
    "    self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var, z = self.encoder(inputs)\n",
    "    reconstructed = self.decoder(z)\n",
    "    # Add KL divergence regularization loss.\n",
    "    kl_loss = - 0.5 * tf.reduce_mean(\n",
    "        z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "    self.add_loss(kl_loss)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 784\n",
    "vae = VariationalAutoEncoder(original_dim, 64, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "step 0: mean loss = tf.Tensor(0.07463287, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.073982626, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.07347118, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.07301432, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.072680764, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.072278194, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.071991295, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.071701154, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.07147088, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.07119507, shape=(), dtype=float32)\n",
      "Start of epoch 1\n",
      "step 0: mean loss = tf.Tensor(0.07113065, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.0709553, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.07082657, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.07067196, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.07058285, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.070422865, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.07031323, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.070190124, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.07009032, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.069967605, shape=(), dtype=float32)\n",
      "Start of epoch 2\n",
      "step 0: mean loss = tf.Tensor(0.0699294, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.06985314, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.069795795, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.06971803, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.06968247, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.06959619, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.069539376, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.06946826, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.069416225, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.06933396, shape=(), dtype=float32)\n",
      "Start of epoch 3\n",
      "step 0: mean loss = tf.Tensor(0.06931701, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.06927472, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.069245756, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.06919925, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.069181636, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.06912298, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.06908763, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.069042526, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.06900679, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.06895259, shape=(), dtype=float32)\n",
      "Start of epoch 4\n",
      "step 0: mean loss = tf.Tensor(0.06894142, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.06891527, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.06889616, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.06886413, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.06885761, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.06881812, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.06879289, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.0687587, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.06873443, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.06869771, shape=(), dtype=float32)\n",
      "Start of epoch 5\n",
      "step 0: mean loss = tf.Tensor(0.06868481, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.068663776, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.06865491, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.068633325, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.068627305, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.068598196, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.06858106, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.06855613, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.068538025, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.068506576, shape=(), dtype=float32)\n",
      "Start of epoch 6\n",
      "step 0: mean loss = tf.Tensor(0.06850104, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.06848773, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.068479724, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.06846627, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.06846228, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.06843812, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.06842626, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.068405285, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.068392925, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.068365656, shape=(), dtype=float32)\n",
      "Start of epoch 7\n",
      "step 0: mean loss = tf.Tensor(0.06836096, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.06835054, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.06834452, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.06833436, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.068332426, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.06831307, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.068302624, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.06828653, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.068276756, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.068253785, shape=(), dtype=float32)\n",
      "Start of epoch 8\n",
      "step 0: mean loss = tf.Tensor(0.06824999, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.06824235, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.06823774, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.0682293, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.06823112, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.06821256, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.06820327, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.068190135, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.06818205, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.06816451, shape=(), dtype=float32)\n",
      "Start of epoch 9\n",
      "step 0: mean loss = tf.Tensor(0.06816017, shape=(), dtype=float32)\n",
      "step 100: mean loss = tf.Tensor(0.068153895, shape=(), dtype=float32)\n",
      "step 200: mean loss = tf.Tensor(0.06815232, shape=(), dtype=float32)\n",
      "step 300: mean loss = tf.Tensor(0.06814254, shape=(), dtype=float32)\n",
      "step 400: mean loss = tf.Tensor(0.06814432, shape=(), dtype=float32)\n",
      "step 500: mean loss = tf.Tensor(0.06813068, shape=(), dtype=float32)\n",
      "step 600: mean loss = tf.Tensor(0.068122216, shape=(), dtype=float32)\n",
      "step 700: mean loss = tf.Tensor(0.068112954, shape=(), dtype=float32)\n",
      "step 800: mean loss = tf.Tensor(0.068104796, shape=(), dtype=float32)\n",
      "step 900: mean loss = tf.Tensor(0.06808872, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Iterate over epochs.\n",
    "for epoch in range(epochs):\n",
    "  print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "  # Iterate over the batches of the dataset.\n",
    "  for step, x_batch_train in enumerate(train_dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "      reconstructed = vae(x_batch_train)\n",
    "      # Compute reconstruction loss\n",
    "      loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "      loss += sum(vae.losses)  # Add KLD regularization loss\n",
    "\n",
    "    grads = tape.gradient(loss, vae.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "\n",
    "    loss_metric(loss)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "      print('step %s: mean loss = %s' % (step, loss_metric.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_latest",
   "language": "python",
   "name": "tf_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
