{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Variational Autoencoder with a STN and Modified Loss function and inverse STN and compare reconstruction loss\n",
    "Removed the classification part \n",
    "Add the cost function of new VAE implementation of Tensorflow documentation\n",
    "This is a MNIST classifier \n",
    "\n",
    "Encoder(Localizaton network) -> CNN to predict affine transformation matrix\n",
    "STN -> Apply affine transformation\n",
    "Decoder -> CNN to classify transformed images from STN\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Activation\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from utils.data_manager import ClutteredMNIST\n",
    "from utils.visualizer import plot_mnist_sample\n",
    "from utils.visualizer import print_evaluation\n",
    "from utils.visualizer import plot_mnist_grid\n",
    "from components.STN import BilinearInterpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./datasets/mnist_cluttered_60x60_6distortions.npz\"\n",
    "batch_size = 256\n",
    "num_epochs = 30\n",
    "\n",
    "data_manager = ClutteredMNIST(dataset_path)\n",
    "train_data, val_data, test_data = data_manager.load()\n",
    "x_train, y_train = train_data\n",
    "plot_mnist_sample(x_train[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "  \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               latent_dim=3,\n",
    "               intermediate_dim=64,\n",
    "               name='encoder',\n",
    "               **kwargs):\n",
    "    super(Encoder, self).__init__(name=name, **kwargs)\n",
    "    self.conv_1 = layers.Conv2D(20, (5, 5), padding='same', activation='relu')\n",
    "    self.max_1 = layers.MaxPool2D(pool_size=(2, 2))\n",
    "    self.conv_2 = layers.Conv2D(20, (5, 5), activation='relu')\n",
    "    self.max_2 = layers.MaxPool2D(pool_size=(2, 2))\n",
    "    \n",
    "    self.flatten = layers.Flatten()\n",
    "    \n",
    "    self.dense_1 = layers.Dense(50, activation='relu')\n",
    "    \n",
    "    self.dense_mean = layers.Dense(3)\n",
    "    self.dense_log_var = layers.Dense(3)\n",
    "    \n",
    "    self.sampling = Sampling()\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.conv_1(inputs)\n",
    "    x = self.max_1(x)\n",
    "    x = self.conv_2(x)\n",
    "    x = self.max_2(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense_1(x)\n",
    "    z_mean = self.dense_mean(x)\n",
    "    z_log_var = self.dense_log_var(x)\n",
    "    z = self.sampling((z_mean, z_log_var))\n",
    "    return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "  \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               num_classes,\n",
    "               intermediate_dim=64,\n",
    "               name='decoder',\n",
    "               **kwargs):\n",
    "    super(Decoder, self).__init__(name=name, **kwargs)\n",
    "    self.conv_1 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n",
    "    self.max_1 = layers.MaxPool2D(pool_size=(2, 2))\n",
    "    self.conv_2 = layers.Conv2D(32, (3, 3), activation='relu')\n",
    "    self.max_2 = layers.MaxPool2D(pool_size=(2, 2))\n",
    "    self.flatten = layers.Flatten()\n",
    "    self.dense_1 = layers.Dense(256, activation='relu')\n",
    "#     self.dense_output = layers.Dense(num_classes, activation='softmax')\n",
    "    self.dense_output = layers.Dense(num_classes)\n",
    "\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.conv_1(inputs)\n",
    "    x = self.max_1(x)\n",
    "    x = self.conv_2(x)\n",
    "    x = self.max_2(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense_1(x)\n",
    "    x = self.dense_output(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.ones((10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.ones(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(tf.keras.Model):\n",
    "  \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               num_classes,\n",
    "               intermediate_dim=64,\n",
    "               latent_dim=3,\n",
    "               name='autoencoder',\n",
    "               **kwargs):\n",
    "    super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
    "    self.num_classes = num_classes\n",
    "    self.encoder = Encoder(latent_dim=latent_dim,\n",
    "                           intermediate_dim=intermediate_dim)\n",
    "    self.stn = BilinearInterpolation((30, 30), name='stn_layer')\n",
    "    self.re_stn = BilinearInterpolation((60, 60), name='stn_layer')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var, z_where = self.encoder(inputs)\n",
    "    n = z_where.shape[0]\n",
    "    \n",
    "    z_where_indexes = tf.repeat([[0,0,1,0,0,2]], n, axis=0)\n",
    "    z_where_selections = tf.repeat([[1.0, 0.0 , 1.0, 0.0, 1.0, 1.0]], n, axis=0)\n",
    "    z_where_modified = tf.gather(z_where, z_where_indexes, batch_dims=1)\n",
    "    z_where_modified = tf.math.multiply(z_where_modified, z_where_selections)\n",
    "    \n",
    "    inverse_z_where =  tf.map_fn(lambda x: x/x[0], z_where)\n",
    "    inverse_z_where_compliments = tf.repeat([[1.0, -1.0 , -1.0]], n, axis=0)    \n",
    "    inverse_z_where = tf.math.multiply(inverse_z_where, inverse_z_where_compliments)\n",
    "    \n",
    "    inverse_z_where_modified = tf.gather(inverse_z_where, z_where_indexes, batch_dims=1)\n",
    "    inverse_z_where_modified = tf.math.multiply(inverse_z_where_modified, z_where_selections)\n",
    "    \n",
    "    \n",
    "    \n",
    "    transformed_image = self.stn([inputs, z_where_modified])\n",
    "    reconstructed_image = self.re_stn([transformed_image, inverse_z_where_modified])\n",
    "    # Add KL divergence regularization loss.\n",
    "    kl_loss = - 0.5 * tf.reduce_mean(\n",
    "        z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "    self.add_loss(kl_loss)\n",
    "    return transformed_image, [z_mean, z_log_var, z_where], reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "vae = VariationalAutoEncoder(num_classes, 64, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "crossentropy_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "iterations = x_train.shape[0] // batch_size\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):  \n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for batch_arg in range(iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            arg_0 = batch_arg * batch_size\n",
    "            arg_1 = (batch_arg + 1) * batch_size\n",
    "            x_batch, y_batch = x_train[arg_0:arg_1], y_train[arg_0:arg_1]\n",
    "            y_batch = y_batch.astype('float32')\n",
    "            \n",
    "            transformed_image, (z_mean, z_log_var, z_where), reconstructed_image = vae(x_batch)\n",
    "            \n",
    "#             cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=classification, labels=y_batch)\n",
    "#             logpx_z = -tf.reduce_sum(cross_ent, axis=[1])\n",
    "#             logpz = log_normal_pdf(z_where, 0., 0.)\n",
    "#             logqz_x = log_normal_pdf(z_where, z_mean, z_log_var)\n",
    "#             loss =  -tf.reduce_mean(logpz - logqz_x)\n",
    "            loss = mse_loss_fn(x_batch, reconstructed_image)\n",
    "            loss += sum(vae.losses)\n",
    "            \n",
    "            \n",
    "#             loss = crossentropy_loss_fn(y_batch, classification)\n",
    "#             loss += sum(vae.losses)\n",
    "        \n",
    "        grads = tape.gradient(loss, vae.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "        \n",
    "        loss_metric(loss)\n",
    "\n",
    "        if batch_arg % 10 == 0:\n",
    "          print('step %s: mean loss = %s' % (batch_arg, loss_metric.result()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = x_train[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vae(visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_grid(visualize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_grid(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_grid(result[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_latest",
   "language": "python",
   "name": "tf_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
